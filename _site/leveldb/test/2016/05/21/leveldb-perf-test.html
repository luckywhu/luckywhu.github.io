<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>leveldb 编译测试</title>
  <meta name="description" content="编译安装跨平台特性比较好，mac下和linux下都直接编译通过，不做任何调整。">

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://luckywhu.github.io/leveldb/test/2016/05/21/leveldb-perf-test.html">
  <link rel="alternate" type="application/rss+xml" title="猴子爱吃鱼的Blog" href="http://luckywhu.github.io/feed.xml">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    <a class="site-title" href="/">猴子爱吃鱼的Blog</a>

    <nav class="site-nav">
      <a href="#" class="menu-icon">
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
      </a>

      <div class="trigger">
        
          
          <a class="page-link" href="/about/">about</a>
          
        
          
        
          
        
          
        
      </div>
    </nav>

  </div>

</header>


    <div class="page-content">
      <div class="wrapper">
        <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title" itemprop="name headline">leveldb 编译测试</h1>
    <p class="post-meta"><time datetime="2016-05-21T01:09:37+08:00" itemprop="datePublished">May 21, 2016</time></p>
  </header>

  <div class="post-content" itemprop="articleBody">
    <h2 id="section">编译安装</h2>
<p>跨平台特性比较好，
mac下和linux下都直接编译通过，不做任何调整。</p>

<ol>
  <li>
    <p>直接编译 make</p>
  </li>
  <li>
    <p>编译并执行单元测试程序  make check，该命令会编译并执行db/XXX_test.cc产出的程序，包含一些单元测试和性能测试工具。</p>
  </li>
</ol>

<h2 id="dbbench">性能测试工具db_bench</h2>
<p>db/db_bench.cc 编译后产出物为db_bench，可以用来做一些基本的性能测试。
不带参数运行输出如下，主要包含两个指标，单次请求的响应时间，以及最终反映出来的IO速率。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>[leveldb]$ ./db_bench 
LevelDB:    version 1.18
CPU:        8 * Intel(R) Xeon(R) CPU           E5620  @ 2.40GHz
CPUCache:   12288 KB
Keys:       16 bytes each
Values:     100 bytes each (50 bytes after compression)
Entries:    1000000
RawSize:    110.6 MB (estimated)
FileSize:   62.9 MB (estimated)
WARNING: Snappy compression is not enabled
------------------------------------------------
fillseq      :       2.843 micros/op;   38.9 MB/s     
fillsync     :    8688.742 micros/op;    0.0 MB/s (1000 ops)
fillrandom   :       4.849 micros/op;   22.8 MB/s     
overwrite    :       5.963 micros/op;   18.6 MB/s     
readrandom   :       5.756 micros/op; (1000000 of 1000000 found)
readrandom   :       4.835 micros/op; (1000000 of 1000000 found)
readseq      :       0.249 micros/op;  444.0 MB/s    
readreverse  :       0.545 micros/op;  202.9 MB/s    
compact      :  803955.000 micros/op;
readrandom   :       3.283 micros/op; (1000000 of 1000000 found)
readseq      :       0.214 micros/op;  516.2 MB/s    
readreverse  :       0.472 micros/op;  234.2 MB/s    
fill100K     :    1430.834 micros/op;   66.7 MB/s (1000 ops)
crc32c       :       5.043 micros/op;  774.6 MB/s (4K per op)
snappycomp   :    5425.000 micros/op; (snappy failure)
snappyuncomp :    4940.000 micros/op; (snappy failure)
acquireload  :       0.847 micros/op; (each op is 1000 loads)
</code></pre>
</div>
<p>从输出看，测试类型包含了顺序写入，随机写入，顺序读取，随机读取等，基本包含了使用中需要关注的所有场景。
由于没有–help参数，所以参数指定需要查看源码获得，修改db_bench.cc，添加一个usage函数，输出帮助文档。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>./db_bench     --db=db_dir          
               --benchmarks=        
               --num=               
               --threads=           
               --value_size=        
               --use_existing_db=   
               --compression_ratio= 
               --histogram=         
               --reads=             
               --cache_size=        
               --bloom_bits=        
               --open_files= 
</code></pre>
</div>
<p>参数的作用如下</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">参数</th>
      <th style="text-align: left">解释</th>
      <th style="text-align: left">默认值</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">–benchamarks</td>
      <td style="text-align: left">测试类型，读，写等</td>
      <td style="text-align: left">默认测试所有的suit</td>
    </tr>
    <tr>
      <td style="text-align: left">–db</td>
      <td style="text-align: left">数据库目录</td>
      <td style="text-align: left">/tmp/leveldb_test_XXX</td>
    </tr>
    <tr>
      <td style="text-align: left">–use_existing_db</td>
      <td style="text-align: left">使用已存在的数据库文件</td>
      <td style="text-align: left">0</td>
    </tr>
    <tr>
      <td style="text-align: left">–num</td>
      <td style="text-align: left">记录行数</td>
      <td style="text-align: left">1000000</td>
    </tr>
    <tr>
      <td style="text-align: left">–threads</td>
      <td style="text-align: left">测试线程数</td>
      <td style="text-align: left">1</td>
    </tr>
    <tr>
      <td style="text-align: left">–reads</td>
      <td style="text-align: left">只读测试中读的次数</td>
      <td style="text-align: left"> </td>
    </tr>
    <tr>
      <td style="text-align: left">–value_size</td>
      <td style="text-align: left">k,v中value的长度</td>
      <td style="text-align: left">默认是100</td>
    </tr>
    <tr>
      <td style="text-align: left">–cache_size</td>
      <td style="text-align: left">LRU的cache大小</td>
      <td style="text-align: left">使用DB的默认值</td>
    </tr>
    <tr>
      <td style="text-align: left">–bloom_bits</td>
      <td style="text-align: left">bloom过滤器bits数</td>
      <td style="text-align: left">使用DB默认值</td>
    </tr>
    <tr>
      <td style="text-align: left">–open_files</td>
      <td style="text-align: left">打开文件数</td>
      <td style="text-align: left">默认1000</td>
    </tr>
    <tr>
      <td style="text-align: left">–compression_ration</td>
      <td style="text-align: left">压缩率，默认snappy压缩</td>
      <td style="text-align: left">0.5</td>
    </tr>
    <tr>
      <td style="text-align: left">–write_buffer_size</td>
      <td style="text-align: left">写入缓冲区大小</td>
      <td style="text-align: left">4MB</td>
    </tr>
  </tbody>
</table>

<p>其中benchmarks可选值如下</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">测试名</th>
      <th style="text-align: left">测试场景</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">fillseq</td>
      <td style="text-align: left">– write N values in sequential key order in async mode</td>
    </tr>
    <tr>
      <td style="text-align: left">fillrandom</td>
      <td style="text-align: left">– write N values in random key order in async mode</td>
    </tr>
    <tr>
      <td style="text-align: left">overwrite</td>
      <td style="text-align: left">– overwrite N values in random key order in async mode</td>
    </tr>
    <tr>
      <td style="text-align: left">fillsync</td>
      <td style="text-align: left">– write N/100 values in random key order in sync mode</td>
    </tr>
    <tr>
      <td style="text-align: left">fill100K</td>
      <td style="text-align: left">– write N/1000 100K values in random order in async mode</td>
    </tr>
    <tr>
      <td style="text-align: left">deleteseq</td>
      <td style="text-align: left">– delete N keys in sequential order</td>
    </tr>
    <tr>
      <td style="text-align: left">deleterandom</td>
      <td style="text-align: left">– delete N keys in random order</td>
    </tr>
    <tr>
      <td style="text-align: left">readseq</td>
      <td style="text-align: left">– read N times sequentially</td>
    </tr>
    <tr>
      <td style="text-align: left">readreverse</td>
      <td style="text-align: left">– read N times in reverse order</td>
    </tr>
    <tr>
      <td style="text-align: left">readrandom</td>
      <td style="text-align: left">– read N times in random order</td>
    </tr>
    <tr>
      <td style="text-align: left">readmissing</td>
      <td style="text-align: left">– read N missing keys in random order</td>
    </tr>
    <tr>
      <td style="text-align: left">readhot</td>
      <td style="text-align: left">– read N times in random order from 1% section of DB</td>
    </tr>
    <tr>
      <td style="text-align: left">seekrandom</td>
      <td style="text-align: left">– N random seeks</td>
    </tr>
    <tr>
      <td style="text-align: left">open</td>
      <td style="text-align: left">– cost of opening a DB</td>
    </tr>
    <tr>
      <td style="text-align: left">crc32c</td>
      <td style="text-align: left">– repeated crc32c of 4K of data</td>
    </tr>
    <tr>
      <td style="text-align: left">acquireload</td>
      <td style="text-align: left">– load N*1000 times</td>
    </tr>
  </tbody>
</table>

<p>##基本测试
比较感兴趣的是大数据量下的读写性能，因此测试了10亿条记录，value_size=300,数据集在280GB的场景。
单线程顺序插入。对db_bench.cc稍作修改，以便同时输出OPS数据。
服务器配置如下，虽然内存较大，但每次测试前均清空Cache</p>

<ol>
  <li>磁盘为单盘450GB的SSD，ext3文件系统，未做RAID。</li>
  <li>CPU为12核心E5620 CPUcache 12MB，</li>
  <li>服务器内存96GB</li>
</ol>

<p>###A.写入测试,单线程fillseq  10亿条记录</p>

<p>单线程写入数据如下，10亿条记录，未压缩size在300GB左右。磁盘IO峰值观察到在60MB/S。
最终体现出来的ops为11.5W/S，平均磁盘IO速度为35MB/S。数据目录下查看有8W多个3.5MB的小文件。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>测试命令
./db_bench --benchmarks=fillseq --db=./db_150G --threads=1 --num=1000000000 --value_size=300 --histogram=1

LevelDB:    version 1.18
CPU:        12 * Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz
CPUCache:   15360 KB
Keys:       16 bytes eachps                              
Values:     300 bytes each (150 bytes after compression)
Entries:    1000000000
RawSize:    301361.1 MB (estimated)
FileSize:   158309.9 MB (estimated)
WARNING: Snappy compression is not enabled
------------------------------------------------
fillseq      :       8.632 micros/op;   34.9 MB/s      115848 op/s 
Microseconds per op:
Count: 1000000000  Average: 8.6323  StdDev: 537.24
Min: 2.0000  Median: 3.8754  Max: 173675.0000
------------------------------------------------------
[       2,       3 ) 7967127   0.797%   0.797% 
[       3,       4 ) 562070985  56.207%  57.004% ###########
[       4,       5 ) 327928783  32.793%  89.797% #######
[       5,       6 ) 13237323   1.324%  91.120% 
[       6,       7 ) 4833270   0.483%  91.604% 
[       7,       8 ) 38261699   3.826%  95.430% #
[       8,       9 ) 30819496   3.082%  98.512% #
[       9,      10 ) 8236891   0.824%  99.336% 
[      10,      12 ) 4430341   0.443%  99.779% 
[      12,      14 ) 1502560   0.150%  99.929% 
[      14,      16 )  284303   0.028%  99.957% 
[      16,      18 )   59401   0.006%  99.963% 
[      18,      20 )   19740   0.002%  99.965% 
[      20,      25 )   28390   0.003%  99.968% 
[      25,      30 )    5991   0.001%  99.969% 
[      30,      35 )    3064   0.000%  99.969% 
[      35,      40 )    5397   0.001%  99.969% 
[      40,      45 )    4382   0.000%  99.970% 
[      45,      50 )    1839   0.000%  99.970% 
[      50,      60 )    2834   0.000%  99.970% 
[      60,      70 )    2356   0.000%  99.971% 
[      70,      80 )    2084   0.000%  99.971% 
[      80,      90 )    2184   0.000%  99.971% 
[      90,     100 )    1767   0.000%  99.971% 
[     100,     120 )    3712   0.000%  99.972% 
[     120,     140 )    3354   0.000%  99.972% 
[     140,     160 )    2916   0.000%  99.972% 
[     160,     180 )    3173   0.000%  99.973% 
[     180,     200 )    3152   0.000%  99.973% 
[     200,     250 )    6253   0.001%  99.973% 
[     250,     300 )    6175   0.001%  99.974% 
[     300,     350 )    5913   0.001%  99.975% 
[     350,     400 )    5066   0.001%  99.975% 
[     400,     450 )    4726   0.000%  99.976% 
[     450,     500 )    5911   0.001%  99.976% 
[     500,     600 )   13321   0.001%  99.978% 
[     600,     700 )   14018   0.001%  99.979% 
[     700,     800 )   11826   0.001%  99.980% 
[     800,     900 )    8459   0.001%  99.981% 
[     900,    1000 )    5015   0.001%  99.982% 
[    1000,    1200 )    5448   0.001%  99.982% 
[    1200,    1400 )    4891   0.000%  99.983% 
[    1400,    1600 )    3869   0.000%  99.983% 
[    1600,    1800 )    4098   0.000%  99.983% 
[    1800,    2000 )    3073   0.000%  99.984% 
[    2000,    2500 )    6602   0.001%  99.984% 
[    2500,    3000 )    3444   0.000%  99.985% 
[    3000,    3500 )    3696   0.000%  99.985% 
[    3500,    4000 )    4428   0.000%  99.985% 
[    4000,    4500 )    4686   0.000%  99.986% 
[    4500,    5000 )    3628   0.000%  99.986% 
[    5000,    6000 )    6455   0.001%  99.987% 
[    6000,    7000 )    9081   0.001%  99.988% 
[    7000,    8000 )    6969   0.001%  99.989% 
[    8000,    9000 )    8653   0.001%  99.989% 
[    9000,   10000 )    7936   0.001%  99.990% 
[   10000,   12000 )   13921   0.001%  99.992% 
[   12000,   14000 )    6197   0.001%  99.992% 
[   14000,   16000 )    4853   0.000%  99.993% 
[   16000,   18000 )    2430   0.000%  99.993% 
[   18000,   20000 )    2238   0.000%  99.993% 
[   20000,   25000 )    5895   0.001%  99.994% 
[   25000,   30000 )    3523   0.000%  99.994% 
[   30000,   35000 )    4799   0.000%  99.995% 
[   35000,   40000 )    7366   0.001%  99.995% 
[   40000,   45000 )    4145   0.000%  99.996% 
[   45000,   50000 )    3736   0.000%  99.996% 
[   50000,   60000 )    8477   0.001%  99.997% 
[   60000,   70000 )    6930   0.001%  99.998% 
[   70000,   80000 )    6620   0.001%  99.998% 
[   80000,   90000 )    5351   0.001%  99.999% 
[   90000,  100000 )    6165   0.001%  99.999% 
[  100000,  120000 )    5191   0.001% 100.000% 
[  120000,  140000 )       7   0.000% 100.000% 
[  160000,  180000 )       2   0.000% 100.000% 
</code></pre>
</div>

<p>###B，随机读取测试，randrandom 10W次
测试前清空Cache.</p>

<p>随机读取10W次，测出性能在2000QPS左右，但磁盘IO维持在130MB/S,iostat中观察到测试分区IO使用率保持在100%。从已阅读的db_bench.cc中对leveldb的使用方式看，OPEN函数可以传进去一个LRUCache，以作缓存block用。对于一次随机读取，leveldb应该需要将该行记录所在的block读到内存，这意味着，如果没有命中cache，为了读300byte的记录，却要完成3.5MB的读IO。这种特性对顺序读取比较好，但对随机IO比较致命。</p>

<p>作为存储引擎，可优化方向</p>

<ul>
  <li>加入行级别缓存</li>
  <li>直接使用SSD随机读，不使用Buffered IO</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>./db_bench --db=./data_150g --threads=1 --reads=100000 --num=1000000000 --value_size=300 --use_existing_db=1 --benchmarks=readrandom --histogram=1      
LevelDB:    version 1.18
CPU:        12 * Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz
CPUCache:   15360 KB
Keys:       16 bytes each
Values:     300 bytes each (150 bytes after compression)
Entries:    1000000000
RawSize:    301361.1 MB (estimated)
FileSize:   158309.9 MB (estimated)
WARNING: Snappy compression is not enabled
------------------------------------------------
readrandom   :     472.792 micros/op; (100000 of 1000000000 found)        2127 op/s 
Microseconds per op:
Count: 100000  Average: 472.7952  StdDev: 765.77
Min: 2.0000  Median: 5.5320  Max: 11067.0000
------------------------------------------------------
[       2,       3 )     282   0.282%   0.282% 
[       3,       4 )   16034  16.034%  16.316% ###
[       4,       5 )   26818  26.818%  43.134% #####
[       5,       6 )   12906  12.906%  56.040% ###
[       6,       7 )    5562   5.562%  61.602% #
[       7,       8 )    3215   3.215%  64.817% #
[       8,       9 )    1244   1.244%  66.061% 
[       9,      10 )     312   0.312%  66.373% 
[      10,      12 )     164   0.164%  66.537% 
[      12,      14 )      22   0.022%  66.559% 
[      14,      16 )      16   0.016%  66.575% 
[      16,      18 )      14   0.014%  66.589% 
[      18,      20 )       8   0.008%  66.597% 
[      20,      25 )      27   0.027%  66.624% 
[      25,      30 )      18   0.018%  66.642% 
[      30,      35 )       2   0.002%  66.644% 
[      35,      40 )       4   0.004%  66.648% 
[      40,      45 )       3   0.003%  66.651% 
[      45,      50 )      50   0.050%  66.701% 
[      50,      60 )     166   0.166%  66.867% 
[      60,      70 )      14   0.014%  66.881% 
[      70,      80 )      14   0.014%  66.895% 
[      80,      90 )      18   0.018%  66.913% 
[      90,     100 )      21   0.021%  66.934% 
[     100,     120 )      61   0.061%  66.995% 
[     120,     140 )      68   0.068%  67.063% 
[     140,     160 )      51   0.051%  67.114% 
[     160,     180 )      35   0.035%  67.149% 
[     180,     200 )      59   0.059%  67.208% 
[     200,     250 )      86   0.086%  67.294% 
[     250,     300 )      50   0.050%  67.344% 
[     300,     350 )      73   0.073%  67.417% 
[     350,     400 )     129   0.129%  67.546% 
[     400,     450 )     198   0.198%  67.744% 
[     450,     500 )     192   0.192%  67.936% 
[     500,     600 )    2939   2.939%  70.875% #
[     600,     700 )    1986   1.986%  72.861% 
[     700,     800 )     197   0.197%  73.058% 
[     800,     900 )     136   0.136%  73.194% 
[     900,    1000 )      83   0.083%  73.277% 
[    1000,    1200 )    2357   2.357%  75.634% 
[    1200,    1400 )    5703   5.703%  81.337% #
[    1400,    1600 )    6440   6.440%  87.777% #
[    1600,    1800 )    6311   6.311%  94.088% #
[    1800,    2000 )    4590   4.590%  98.678% #
[    2000,    2500 )     834   0.834%  99.512% 
[    2500,    3000 )       5   0.005%  99.517% 
[    3000,    3500 )       3   0.003%  99.520% 
[    3500,    4000 )       8   0.008%  99.528% 
[    4000,    4500 )      95   0.095%  99.623% 
[    4500,    5000 )     106   0.106%  99.729% 
[    5000,    6000 )     205   0.205%  99.934% 
[    6000,    7000 )      55   0.055%  99.989% 
[    7000,    8000 )       5   0.005%  99.994% 
[    8000,    9000 )       1   0.001%  99.995% 
[    9000,   10000 )       1   0.001%  99.996% 
[   10000,   12000 )       4   0.004% 100.000% 
</code></pre>
</div>

<p>###C 顺序读取测试，readseq 1000W次
测试前清空Cache。</p>

<p>批量读取性能接近300MB/S，换算为QPS为100W/S。曾经测试过的Innodb批量读取速度在20W行左右，因为Innodb的Page Size只有16KB，作为存储引擎应对大范围Rang查询性能足够。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>./db_bench --db=./data_150g --threads=1 --reads=10000000 --num=1000000000 --value_size=300 --use_existing_db=1 --benchmarks=readseq --histogram=1
LevelDB:    version 1.18
CPU:        12 * Intel(R) Xeon(R) CPU E5-2620 v2 @ 2.10GHz
CPUCache:   15360 KB
Keys:       16 bytes each
Values:     300 bytes each (150 bytes after compression)
Entries:    1000000000
RawSize:    301361.1 MB (estimated)
FileSize:   158309.9 MB (estimated)
WARNING: Snappy compression is not enabled
------------------------------------------------
readseq      :       1.022 micros/op;  295.0 MB/s     1000000 op/s 
Microseconds per op:
Count: 10000000  Average: 1.0215  StdDev: 24.70
Min: 0.0000  Median: 0.8486  Max: 16578.0000
------------------------------------------------------
[       0,       1 ) 5892071  58.921%  58.921% ############
[       1,       2 ) 3369861  33.699%  92.619% #######
[       2,       3 )  559748   5.597%  98.217% #
[       3,       4 )  142351   1.424%  99.640% 
[       4,       5 )    7182   0.072%  99.712% 
[       5,       6 )    1844   0.018%  99.731% 
[       6,       7 )     960   0.010%  99.740% 
[       7,       8 )     133   0.001%  99.742% 
[       8,       9 )      74   0.001%  99.742% 
[       9,      10 )      75   0.001%  99.743% 
[      10,      12 )      99   0.001%  99.744% 
[      12,      14 )     104   0.001%  99.745% 
[      14,      16 )      54   0.001%  99.746% 
[      16,      18 )      30   0.000%  99.746% 
[      18,      20 )      49   0.000%  99.746% 
[      20,      25 )      77   0.001%  99.747% 
[      25,      30 )     111   0.001%  99.748% 
[      30,      35 )     374   0.004%  99.752% 
[      35,      40 )    1350   0.014%  99.765% 
[      40,      45 )    1066   0.011%  99.776% 
[      45,      50 )     124   0.001%  99.777% 
[      50,      60 )      26   0.000%  99.778% 
[      60,      70 )      11   0.000%  99.778% 
[      70,      80 )     127   0.001%  99.779% 
[      80,      90 )    1143   0.011%  99.790% 
[      90,     100 )    2921   0.029%  99.820% 
[     100,     120 )    8742   0.087%  99.907% 
[     120,     140 )     233   0.002%  99.909% 
[     140,     160 )     213   0.002%  99.912% 
[     160,     180 )     461   0.005%  99.916% 
[     180,     200 )     532   0.005%  99.921% 
[     200,     250 )    1578   0.016%  99.937% 
[     250,     300 )    3183   0.032%  99.969% 
[     300,     350 )    1149   0.011%  99.981% 
[     350,     400 )     111   0.001%  99.982% 
[     400,     450 )      16   0.000%  99.982% 
[     450,     500 )      10   0.000%  99.982% 
[     500,     600 )      11   0.000%  99.982% 
[     600,     700 )      38   0.000%  99.982% 
[     700,     800 )     641   0.006%  99.989% 
[     800,     900 )     962   0.010%  99.998% 
[     900,    1000 )      46   0.000%  99.999% 
[    1000,    1200 )      18   0.000%  99.999% 
[    1200,    1400 )      11   0.000%  99.999% 
[    1400,    1600 )       1   0.000%  99.999% 
[    1600,    1800 )       2   0.000%  99.999% 
[    1800,    2000 )       6   0.000%  99.999% 
[    2000,    2500 )       3   0.000%  99.999% 
[    2500,    3000 )       4   0.000%  99.999% 
[    3000,    3500 )       5   0.000%  99.999% 
[    3500,    4000 )       2   0.000%  99.999% 
[    4000,    4500 )       3   0.000%  99.999% 
[    4500,    5000 )       9   0.000% 100.000% 
[    5000,    6000 )       1   0.000% 100.000% 
[    8000,    9000 )      10   0.000% 100.000% 
[    9000,   10000 )      33   0.000% 100.000% 
[   16000,   18000 )       1   0.000% 100.000% 

</code></pre>
</div>

<p>###D，随机覆盖写入 fillrandom
由于db_bench中没有指定write次数的参数，写入时只能用num参数，和表行数相同，10亿条记录的全量覆盖写入时间非常长，因此需要修改db_bench.cc,增加–writes参数，结果待给出</p>


  </div>

</article>

      </div>
    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h2 class="footer-heading">猴子爱吃鱼的Blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li>猴子爱吃鱼的Blog</li>
          <li><a href="mailto:jianyingse@gmail.com">jianyingse@gmail.com</a></li>
        </ul>
      </div>

      <div class="footer-col footer-col-2">
        <ul class="social-media-list">
          
          <li>
            <a href="https://github.com/luckywhu"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span><span class="username">luckywhu</span></a>

          </li>
          

          
          <li>
            <a href="https://twitter.com/jianyingse"><span class="icon icon--twitter"><svg viewBox="0 0 16 16"><path fill="#828282" d="M15.969,3.058c-0.586,0.26-1.217,0.436-1.878,0.515c0.675-0.405,1.194-1.045,1.438-1.809c-0.632,0.375-1.332,0.647-2.076,0.793c-0.596-0.636-1.446-1.033-2.387-1.033c-1.806,0-3.27,1.464-3.27,3.27 c0,0.256,0.029,0.506,0.085,0.745C5.163,5.404,2.753,4.102,1.14,2.124C0.859,2.607,0.698,3.168,0.698,3.767 c0,1.134,0.577,2.135,1.455,2.722C1.616,6.472,1.112,6.325,0.671,6.08c0,0.014,0,0.027,0,0.041c0,1.584,1.127,2.906,2.623,3.206 C3.02,9.402,2.731,9.442,2.433,9.442c-0.211,0-0.416-0.021-0.615-0.059c0.416,1.299,1.624,2.245,3.055,2.271 c-1.119,0.877-2.529,1.4-4.061,1.4c-0.264,0-0.524-0.015-0.78-0.046c1.447,0.928,3.166,1.469,5.013,1.469 c6.015,0,9.304-4.983,9.304-9.304c0-0.142-0.003-0.283-0.009-0.423C14.976,4.29,15.531,3.714,15.969,3.058z"/></svg>
</span><span class="username">jianyingse</span></a>

          </li>
          
        </ul>
      </div>

      <div class="footer-col footer-col-3">
        <p>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
</p>
      </div>
    </div>

  </div>

</footer>


  </body>

</html>
